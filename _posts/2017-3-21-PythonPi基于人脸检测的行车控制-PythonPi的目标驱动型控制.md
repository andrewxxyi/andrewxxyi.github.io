---
layout: post
title: PythonPi基于人脸检测的行车控制-PythonPi的目标驱动型控制
date: 2017-3-21
---
前文（[分布式智能控制](http://115.29.52.95/forum.php?mod=forumdisplay&fid=40)）说了：现代控制系统基本都是反馈型的控制。因此PythonPi实际上并无必要提供一个所谓的反馈控制的功能。我们讲过我们的控制系统是包括传感器、执行器、裁决器的，而当代的控制核心都是计算机控制，实际上，现代的控制系统都是：

- 从传感器采集信号来了解当前的系统状态和环境状态

- 根据预置的知识体系（模型库、事实库、规则库）对现场采集到的状态信息进行理解与逻辑推理，以决定控制动作

- 执行控制动作，如果系统较复杂，这里的执行可能还会是递阶控制，即分解为低层子系统的控制目标，由子系统进行更精细的控制

- 再次采集信号来检查控制动作执行的效果，如果必要则再次发出调控指令

简单点看，控制系统的功能框架是：

  ![控制系统框架](http://course.pythonpi.top:10008/images/控制系统框架.png)

因此，现代的控制系统都是反馈型的，只是看决策环节中在了解到当前状态后如何决定控制动作时，是更多的采取预测（需要更多的知识）还是修正（所需知识较少）而已。

但是，我们上次也说了，之前我们介绍的控制功能都是固定响应式控制的。主要有两种：

- 类似摇杆来进行小车遥控功能，这种控制是采集信号，经过变换直接生成控制信号（摇杆生成方位角和出力两种信号）发送给小车的驱动部分执行

- 类似综合安防系统，这种控制的核心是精心画出相应功能的状态跃迁图，然后将各传感器的输入信号转换为相应的事件，实现了基于事件的应激控制

这两种类型的控制功能，基本可以涵盖安防、智能家居、自控、机电控制等领域，我们称之为事件驱动型控制。不过我们需要注意到，这些领域都有一个特点，就是应用环境的固化，一般来说都具有系统功能单一、环境固定、控制机制清晰等特点。但随着信息系统越来越廉价、性价比越来越高，即便是上述领域也出现了智能化、个性化控制的要求，在未来，随便一个功能也很可能涉及到数十上百个传感器、执行器参与其中，而且最重要的，这些传感器执行器可能还是动态参与到控制场景中来的，这种情况下想清晰的画出系统状态跃迁图就有些困难了。

针对这种趋势，PythonPi提供了目标驱动型的控制功能。目标驱动型控制的思路大致是：

- 给定任务的目标

- 将任务分解为子任务

- 将任务目标分解为子任务的子目标

- 规划子任务的执行路径

- 驱动子任务的执行

- 子任务执行完毕检查任务目标的完成情况，如果没有达到目标则重复上述步骤

这样一来，PythonPi中的控制功能将有两类：

- 事件驱动型控制，类比于人的条件反射，一般用于简单、低层次的、重复性的日常控制

- 目标驱动型控制，类比于人的高级神经活动（如初次开车、写作、作战等），一般用于复杂的、动态的控制功能，如自动驾驶、使命必达的东方快递（DF26）

这两者本质的区别就是在于事件驱动型控制的决策环节是固化的，而目标驱动型控制的决策环节是动态的。如果以目前火的厉害的深度学习来类比，则事件驱动型控制是已经学习、训练好的；而目标驱动型控制则处于学习过程中，无法直接用模型计算结果而只能动用各种技术手段对输入的每个信号进行处理，然后观察处理结果，如果结果较好，则可以将输入、处理动作、结果作为正例加以采集，反之可以作为反例加以采集，当积累的样本足够多了之后，就可以计算模型了。而当模型计算出来后，就可以转为事件驱动型控制来节省计算资源并加速控制过程，这也是对人类学习过程的模拟。

对于PythonPi，事件驱动型控制已经非常成熟了，目标驱动型控制尚处于发展阶段。下面我们会以基于人脸检测的行车控制来讲解PythonPi平台中的目标驱动型控制

====================================================================================================

`关注我的公众号及时获取推送的最新文章`

  ![公众号](http://course.pythonpi.top:10008/images/qrcode.jpg)

